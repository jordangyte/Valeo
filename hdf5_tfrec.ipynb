{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocker sous HDF5\n",
    "\n",
    "De façon à simplifier l'importation des images, j'ai fait le choix d'utiliser un fichier hdf5 plutôt que d'importer les images depuis le dossier. Les répertoires normaux prennent plus de place, sont inefficaces pour l'itération, ne supportent pas les entrées/sorties parallèles, l'accès aléatoire, sont non hétérogènes. La démarche adoptée ici est de lire chaque image dans le dossier, puis de l'envoyer vers une fonction de prétraitement puis de l'analyser pour obtenir un tableau numérique global qui pourra ensuite être utilisé pour créer un fichier hdf5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "#sélectionner le dossier à transformer 'train' ou 'test'\n",
    "folder = 'test'\n",
    "\n",
    "#déterminer une valeur pour recadrer l'image (max 2070px)\n",
    "IMAGE_RESIZED = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE PATH\n",
    "save_path = folder+'_dataset.hdf5'\n",
    "img_path = folder+'_dataset/*.jpg'\n",
    "\n",
    "files = glob.glob(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers : 1989\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de fichiers : {}\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_dataset/AE00022_095817_00_1_1_2001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_dataset/AE00382_081204_00_3_4_2001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_dataset/AE00281_235123_00_2_1_2001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_dataset/AE00408_051313_00_4_4_2001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_dataset/AE00379_034020_00_1_2_2001.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        images  labels\n",
       "0  test_dataset/AE00022_095817_00_1_1_2001.jpg     NaN\n",
       "1  test_dataset/AE00382_081204_00_3_4_2001.jpg     NaN\n",
       "2  test_dataset/AE00281_235123_00_2_1_2001.jpg     NaN\n",
       "3  test_dataset/AE00408_051313_00_4_4_2001.jpg     NaN\n",
       "4  test_dataset/AE00379_034020_00_1_2_2001.jpg     NaN"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTER LES LABELS\n",
    "labels = pd.read_csv(folder+'_data_labels.csv')\n",
    "labels['images'] = folder+'_dataset/' + labels['images'].astype(str)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 1000/10609\n",
      "train data: 2000/10609\n",
      "train data: 3000/10609\n",
      "train data: 4000/10609\n",
      "train data: 5000/10609\n",
      "train data: 6000/10609\n",
      "train data: 7000/10609\n",
      "train data: 8000/10609\n",
      "train data: 9000/10609\n",
      "train data: 10000/10609\n"
     ]
    }
   ],
   "source": [
    "shape = (len(files), IMAGE_RESIZED, IMAGE_RESIZED, 3)\n",
    "\n",
    "with h5py.File(save_path,'w') as f:\n",
    "    f.create_dataset(folder+'_img', shape, np.uint8)\n",
    "    f.create_dataset(\"labels\", (len(files),), np.uint8)\n",
    "    f[\"labels\"][...] = labels['labels'] #stocker les labels\n",
    "    \n",
    "    for i in range(len(labels['images'])):\n",
    "        \n",
    "        if i % 1000 == 0 and i > 1:\n",
    "            print (folder+' data: {}/{}'.format(i, len(files)) ) #pour suivre l'évolution\n",
    "\n",
    "        path = labels.loc[i, 'images']\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (IMAGE_RESIZED, IMAGE_RESIZED), interpolation=cv2.INTER_CUBIC) # recadrer à la taille voulue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 charger les images en BGR puis convertir en RGB\n",
    "        f[folder+'_img'][i, ...] = img[None] #stocker les images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocker sous TFRecord\n",
    "\n",
    "Faisant face à une saturation de la mémoire dès lors la taille des images dépassait 150x150px, j'ai décidé de formater mes images vers le format TFRecord, optimisé pour l'usage de Tensorflow et cela s'est avéré efficace. Pour en savoir plus sur ce format, je conseille de consulter cet [article](https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564). La source du code provient de ce [notebook](https://www.kaggle.com/cdeotte/how-to-create-tfrecords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHARGEMENT DES LIBRAIRES\n",
    "import numpy as np, pandas as pd, os\n",
    "import matplotlib.pyplot as plt, cv2\n",
    "import tensorflow as tf, re, math\n",
    "\n",
    "#SELECTIONNER LE DOSSIER A FORMATER 'train' OU 'test'\n",
    "folder = 'test'\n",
    "\n",
    "#TAILLE DE L'IMAGE A RE-AJUSTER\n",
    "IMAGE_RESIZED = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1989 train images\n"
     ]
    }
   ],
   "source": [
    "#CHEMIN VERS LES IMAGES\n",
    "PATH = folder+'_dataset/'\n",
    "IMGS = os.listdir(PATH)\n",
    "print('There are %i train images'%(len(IMGS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE00022_095817_00_1_1_2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE00382_081204_00_3_4_2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE00281_235123_00_2_1_2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE00408_051313_00_4_4_2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE00379_034020_00_1_2_2001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       images  labels\n",
       "0  AE00022_095817_00_1_1_2001       0\n",
       "1  AE00382_081204_00_3_4_2001       0\n",
       "2  AE00281_235123_00_2_1_2001       0\n",
       "3  AE00408_051313_00_4_4_2001       0\n",
       "4  AE00379_034020_00_1_2_2001       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORTER LES LABELS\n",
    "labels = pd.read_csv(folder+'_data_labels.csv')\n",
    "labels['images'] = folder+'_dataset/' + labels['images'].astype(str)\n",
    "labels['images'] = labels['images'].str.split(pat='/', expand=True)[1]\n",
    "labels['images'] = labels['images'].str.split(pat='.', expand=True)[0]\n",
    "labels['labels'] = labels['labels'].fillna(0)\n",
    "labels['labels'] = labels['labels'].astype('int')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy()\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2):\n",
    "  feature = {\n",
    "      'image': _bytes_feature(feature0),\n",
    "      'image_name': _bytes_feature(feature1),\n",
    "      'label': _int64_feature(feature2)\n",
    "  }\n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing TFRecord 0 of 1...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , "
     ]
    }
   ],
   "source": [
    "SIZE = 2071\n",
    "CT = len(IMGS)//SIZE + int(len(IMGS)%SIZE!=0)\n",
    "for j in range(CT):\n",
    "    print(); print('Writing TFRecord %i of %i...'%(j,CT))\n",
    "    CT2 = min(SIZE,len(IMGS)-j*SIZE)\n",
    "    with tf.io.TFRecordWriter(folder+'%.2i-%i.tfrec'%(j,CT2)) as writer:\n",
    "        for k in range(CT2):\n",
    "            img = cv2.imread(PATH+IMGS[SIZE*j+k])\n",
    "            img = cv2.resize(img, (IMAGE_RESIZED, IMAGE_RESIZED), interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n",
    "            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n",
    "            name = IMGS[SIZE*j+k].split('.')[0]\n",
    "            row = labels.loc[labels.images==name]\n",
    "            example = serialize_example(img, str.encode(name), row.labels.values[0])\n",
    "            writer.write(example)\n",
    "            if k%100==0: print(k,', ',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
